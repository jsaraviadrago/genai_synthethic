{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# This the task for GEN-AI from Vincent's Granvilles book \"Synthetic Data and Generative AI\"\n",
    "\n",
    "The first thing is to import the packages"
   ],
   "id": "99a030b922322153"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-22T22:25:05.594270Z",
     "start_time": "2024-07-22T22:25:05.570538Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy.stats import ks_2samp\n",
    "from statsmodels.distributions.empirical_distribution import ECDF\n",
    "from scipy.stats import norm\n",
    "import csv\n",
    "\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Reading the data from Github from the Vincent Granville's [repo](https://github.com/VincentGranville/Main) \n",
    "\n",
    "The link for the project book is [here](https://github.com/VincentGranville/Large-Language-Models/blob/main/Projects4.pdf)"
   ],
   "id": "fb7cc49a2e0153a3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T00:22:12.251489Z",
     "start_time": "2024-07-23T00:22:11.461141Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Selecting the needed data frames according to the project book. \n",
    "insurance = 'insurance.csv'\n",
    "insurance_compare = 'insurance_compare.csv'\n",
    "insurance_compare_holdout = 'insurance_compare_holdout.csv'\n",
    "insurance_compare_train = 'insurance_compare_train.csv'\n",
    "insurance_compare_test = 'insurance_compare_test.csv'\n",
    "\n",
    "\n",
    "# Getting the URL\n",
    "url = \"https://raw.githubusercontent.com/VincentGranville/Main/main/\"\n",
    "url2 = \"https://raw.githubusercontent.com/jsaraviadrago/genai_synthethic/main/\"\n",
    "\n",
    "# Separating the raw data frames\n",
    "raw_insurance =  url + insurance \n",
    "raw_insurance_compare = url + insurance_compare \n",
    "raw_insurance_compare_update = url2 + insurance_compare\n",
    "raw_insurance_compare_holdout = url + insurance_compare_holdout\n",
    "raw_insurance_compare_train = url2 + insurance_compare_train\n",
    "raw_insurance_compare_test = url2 + insurance_compare_test\n",
    "\n",
    "# Opening the links with pandas.\n",
    "df_insurance = pd.read_csv(raw_insurance) #step 1\n",
    "df_insurance_compare = pd.read_csv(raw_insurance_compare) # step 2\n",
    "df_insurance_compare_update = pd.read_csv(raw_insurance_compare_update) #step 3 to add the generated data\n",
    "df_insurance_compare_holdout = pd.read_csv(raw_insurance_compare_holdout) #step 3 to understand what should be the result\n",
    "df_insurance_compare_train = pd.read_csv(raw_insurance_compare_train) # step 3 get the training set from the repo\n",
    "df_insurance_compare_test = pd.read_csv(raw_insurance_compare_test) # step 3 get the training set from the repo\n",
    "\n"
   ],
   "id": "c7cced62241d1f8b",
   "outputs": [],
   "execution_count": 116
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Step 1: Making the histograms for the numerical variables ",
   "id": "aa25d2d542ee9d25"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig, axs = plt.subplots(2, 2)\n",
    "axs[0, 0].hist(df_insurance['age'])\n",
    "axs[0, 0].set_title(\"Age\")\n",
    "axs[1, 0].hist(df_insurance['charges'])\n",
    "axs[1, 0].set_title(\"Charges\")\n",
    "axs[0, 1].hist(df_insurance['bmi'])\n",
    "axs[0, 1].set_title(\"Bmi\")\n",
    "fig.tight_layout()\n",
    "\n",
    "\n"
   ],
   "id": "b0e1292e7cd095cd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Step 2: perform evaluations of vendor comparisons\n",
    "\n",
    "Preparing the data to make some analysis. \n",
    "- Drop columns\n",
    "- Erase NA values"
   ],
   "id": "f5d626f00232f499"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T00:22:18.550617Z",
     "start_time": "2024-07-23T00:22:18.536260Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Watch out with this code, since I am overwriting the dataset you need to run first the second cell or an error will be thrown. This can be fixed if you use a script. \n",
    "\n",
    "df_insurance_compare = df_insurance_compare.drop('region', axis=1) # drop columns that are not useful\n",
    "df_insurance_compare = df_insurance_compare.dropna(axis='columns') # Drop na row wise. \n",
    "\n",
    "# Create a dataset of insurance compare with only Real category\n",
    "df_insurance_compare_real = df_insurance_compare.loc[df_insurance_compare['Data'] == 'Real'] \n",
    "\n",
    "df_insurance_compare_real = df_insurance_compare_real.drop('Data', axis=1) # drop all the NA values from Data column\n",
    "df_insurance_compare_real = df_insurance_compare_real.to_numpy() # this transforms the code into a matrix in order to run the next line of code.\n"
   ],
   "id": "707a468d582fa2b9",
   "outputs": [],
   "execution_count": 117
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Step 2.1: run the analysis after preparing the data\n",
    "\n",
    "What did I do here? \n",
    "- Correlation matrix\n",
    "- Drop the real category from the original data frame called ```df_insurance_compare```"
   ],
   "id": "e71c6f6bf4d6fc62"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "edb2c5c5735f8b8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T00:22:31.862425Z",
     "start_time": "2024-07-23T00:22:31.853877Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Making a correlation matrix with coefficients\n",
    "r_corr = np.corrcoef(df_insurance_compare_real.T) # Here you need to transpose the data so it makes sense\n",
    "\n",
    "#r_corr # this code prints the correlation matrix. Note if I use print it also works the only differences is that it outputs in pure python form\n",
    "\n",
    "ltests = df_insurance_compare.Data.unique().tolist() # Here it just shows all the unique categories of the Data variable\n",
    "popped_item = ltests.pop(0)   # remove real data from the tests\n",
    "print(ltests) # it just prints that the ltests object does not have the \"Real\" category\n",
    "\n"
   ],
   "id": "631d0b20e21e406",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['YData1', 'YData2', 'Gretel', 'SDV', 'Synthesize.io', 'VG_Copula', 'Mostly.ai']\n"
     ]
    }
   ],
   "execution_count": 118
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T00:22:51.468473Z",
     "start_time": "2024-07-23T00:22:51.456798Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "d42c17de026d3cfc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.02085587,  0.10927188,  0.042469  , -0.02501875,\n",
       "         0.29900819],\n",
       "       [ 0.02085587,  1.        , -0.04637115, -0.01716298, -0.07618482,\n",
       "        -0.05729207],\n",
       "       [ 0.10927188, -0.04637115,  1.        ,  0.0127589 ,  0.00375043,\n",
       "         0.19834098],\n",
       "       [ 0.042469  , -0.01716298,  0.0127589 ,  1.        ,  0.00767312,\n",
       "         0.06799823],\n",
       "       [-0.02501875, -0.07618482,  0.00375043,  0.00767312,  1.        ,\n",
       "         0.78725143],\n",
       "       [ 0.29900819, -0.05729207,  0.19834098,  0.06799823,  0.78725143,\n",
       "         1.        ]])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 119
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Step 2.2: run the analysis to check for the data\n",
    "\n",
    "- Calculate the distance of the correlation matrix\n",
    "- Calculate the distance of the Kolmogorov-Smirnov "
   ],
   "id": "93582734727abd32"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T00:23:33.658710Z",
     "start_time": "2024-07-23T00:23:33.579799Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for test in ltests:\n",
    "\n",
    "    data_test = df_insurance_compare.loc[df_insurance_compare['Data'] == test] # select the category test\n",
    "    data_test = data_test.drop('Data', axis=1) # Drop the column Data from the test_data\n",
    "    data_test = data_test.to_numpy() # change the data frame into a matrix\n",
    "    t_corr = np.corrcoef(data_test.T) # Run a correlation matrix\n",
    "    delta = np.abs(t_corr - r_corr) # calculating the delta or difference between the correlation matrices of both test sets. The nearest to 0 the best match. \n",
    "    dim = delta.shape[0]   # number of features\n",
    "  \n",
    "    ks = np.zeros(dim) # Here I want to calculate the Kolmogorov-Smirnov distance remember that the lower the distance the better. Lower distance means more similarity. \n",
    "    out_of_range = 0\n",
    "    for idx in range(dim): # This for loop just loops throw all the m columns \n",
    "        dr = df_insurance_compare_real[:,idx]\n",
    "        dt = data_test[:,idx]\n",
    "        stats = ks_2samp(dr, dt)\n",
    "        ks[idx] = stats.statistic # Calculate the Kolmogorov-Smirnov distance throw all the columns\n",
    "        if np.min(dt) < np.min(dr) or np.max(dt) > np.max(dr):\n",
    "            out_of_range = 1\n",
    "    str = \"%20s %14s %8.6f %8.6f %8.6f %8.6f %1d\" % (insurance_compare, test, np.mean(delta), \n",
    "              np.max(delta), np.mean(ks), np.max(ks), out_of_range)\n",
    "    print(str)\n",
    "    \n"
   ],
   "id": "a1a45888a898a7d5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "insurance_compare.csv         YData1 0.015844 0.051774 0.020227 0.030059 0\n",
      "insurance_compare.csv         YData2 0.017100 0.052157 0.022297 0.028401 0\n",
      "insurance_compare.csv         Gretel 0.021085 0.092606 0.040011 0.086254 0\n",
      "insurance_compare.csv            SDV 0.033703 0.350682 0.093176 0.213358 0\n",
      "insurance_compare.csv  Synthesize.io 0.025702 0.070506 0.025870 0.040396 0\n",
      "insurance_compare.csv      VG_Copula 0.013471 0.049100 0.016442 0.032885 0\n",
      "insurance_compare.csv      Mostly.ai 0.017264 0.057882 0.023169 0.041854 0\n"
     ]
    }
   ],
   "execution_count": 120
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "e752f7b3d92d5a75"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Step 2.3: create the scatterplot\n",
    "\n",
    "Creating a function for the scatterplot\n",
    "\n"
   ],
   "id": "20bd3b6fbf0b3a4a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def vg_scatter(df_insurance_compare, test, counter):\n",
    "\n",
    "    # customized plots, insurance data \n",
    "    # one of 6 plots, subplot position based on counter\n",
    "\n",
    "    data_plot = df_insurance_compare.loc[df_insurance_compare['Data'] == test]\n",
    "    x = data_plot[['age']].to_numpy()\n",
    "    y = data_plot[['charges']].to_numpy()\n",
    "    plt.subplot(2, 3, counter)\n",
    "    plt.scatter(x, y, s = 0.1, c =\"blue\")\n",
    "    plt.xlabel(test, fontsize = 7)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.ylim(0,70000)\n",
    "    plt.xlim(18,64)\n",
    "    return()\n",
    "\n",
    "# Set the linewidth for axes\n",
    "mpl.rcParams['axes.linewidth'] = 0.3\n",
    "\n",
    "# Plot each scatter plot\n",
    "vg_scatter(df_insurance_compare, 'Real', 1)\n",
    "vg_scatter(df_insurance_compare, 'YData1', 2)\n",
    "vg_scatter(df_insurance_compare, 'Gretel', 3)\n",
    "vg_scatter(df_insurance_compare, 'Mostly.ai', 4)\n",
    "vg_scatter(df_insurance_compare, 'Synthesize.io', 5)\n",
    "vg_scatter(df_insurance_compare, 'SDV', 6)\n",
    "\n",
    "plt.tight_layout() # Just to fit it in a nice size. \n",
    "plt.show()\n",
    "\n"
   ],
   "id": "419afe81ed7c0460",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Step 2.4: Create the histogram\n",
    "\n",
    "Creating a function for the histogram and plotting the histogram\n",
    "\n",
    "\n"
   ],
   "id": "91c054a1a4afbd58"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def vg_histo(df, test, counter):\n",
    "\n",
    "    # customized plots, insurance data \n",
    "    # one of 6 plots, subplot position based on counter\n",
    "\n",
    "    data_plot = df_insurance_compare.loc[df['Data'] == test]\n",
    "    y = data_plot[['charges']].to_numpy()\n",
    "    plt.subplot(2, 3, counter)\n",
    "    binBoundaries = np.linspace(0, 70000, 30)\n",
    "    plt.hist(y, bins=binBoundaries, color='white', align='mid',edgecolor='red',\n",
    "              linewidth = 0.3) \n",
    "    plt.xlabel(test, fontsize = 7)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.xlim(0,70000)\n",
    "    plt.ylim(0, 250)\n",
    "    return()\n",
    "\n",
    "# Set the linewidth for axes\n",
    "mpl.rcParams['axes.linewidth'] = 0.3\n",
    "\n",
    "vg_histo(df_insurance_compare, 'Real', 1)\n",
    "vg_histo(df_insurance_compare, 'YData1', 2)\n",
    "vg_histo(df_insurance_compare, 'Gretel', 3)\n",
    "vg_histo(df_insurance_compare, 'Mostly.ai', 4)\n",
    "vg_histo(df_insurance_compare, 'Synthesize.io', 5)\n",
    "vg_histo(df_insurance_compare, 'SDV', 6)\n",
    "\n",
    "plt.tight_layout() # Just to fit it in a nice size. \n",
    "plt.show()"
   ],
   "id": "5fd74a26f9dd723d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Step 3: Produce a file similar to insurance compare holdout.csv but for a vendor other than YData.ai\n",
    "\n",
    "The holdout data has 50% of the rows of validate, train and Ydata. There is also 669 Ydata2 which is the synthethic data. So, in order to start working with the insurance_compare data you need to first use the first half of the real category as explained in the book. \n",
    "\n",
    "**Note:** Probably in other methods you could hold data randomly. \n"
   ],
   "id": "97fdbe66cabc5cc6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_insurance_compare_holdout.info() # inspecting the whole data frame\n",
    "\n",
    "# Inspecting the data there 4 categories and Ydata1 has been used to create 669 new rows named Ydata2\n",
    "df_insurance_compare_holdout['Data'].value_counts() # counting categories of data\n",
    "\n"
   ],
   "id": "a4473b2b84d8754a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "b38b774eb37f30da"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Step 3.1: this was done in the script. Script_insurance_synthethic_data.py",
   "id": "fbce323164ba8f4c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T00:24:30.143181Z",
     "start_time": "2024-07-23T00:24:29.849440Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Calling the output data from that script.\n",
    "\n",
    "synthetic_data = 'insurance_synth.txt'\n",
    "\n",
    "raw_data_synthetic = url2+synthetic_data\n",
    "synthethic_data_csv = pd.read_csv(raw_data_synthetic, sep=\"\\t\", header=None)\n",
    "synthethic_data_csv.columns = [\"sex\", \"smoker\", \"region\", \"age\", \"bmi\", \"children\", \"charges\"]\n",
    "synthethic_data_csv['Data'] = \"Synthetic\"\n",
    "synthethic_data_csv = synthethic_data_csv[['Data', 'age', 'sex', 'bmi', 'children', 'smoker', 'region', 'charges']]\n",
    "\n",
    "# This data in CSV is the first generated data called synthethic_data.csv\n",
    "\n",
    "\n"
   ],
   "id": "87161f410d5d5ed5",
   "outputs": [],
   "execution_count": 121
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T00:24:33.722199Z",
     "start_time": "2024-07-23T00:24:33.716377Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Making the data similar to the synthethic_data.csv to test against the test\n",
    "df_insurance_compare_test = df_insurance_compare_test.drop(['Unnamed: 0','Unnamed: 8', 'Unnamed: 9', 'Unnamed: 10'],axis=1)"
   ],
   "id": "b2616a1baa299861",
   "outputs": [],
   "execution_count": 122
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Now check the quality of the synthethization using the correlation distance matrix and KM distance\n",
    "\n",
    "- First we make both datasets the same\n",
    "- Checking the quality of the data"
   ],
   "id": "c9e4d13547a0ad76"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T00:24:42.010305Z",
     "start_time": "2024-07-23T00:24:41.997391Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Now check the quality of the synthethization using the correlation distance matrix and KM distance\n",
    "\n",
    "synthethic_data_csv_VF = synthethic_data_csv[:-1] # Dropping the last row so both datasets have the same amount of lines\n",
    "\n",
    "synthethic_data_csv_VF = synthethic_data_csv_VF.drop('region', axis=1) # drop columns that are not useful\n",
    "synthethic_data_csv_VF = synthethic_data_csv_VF.dropna(axis='columns') # Drop na row wise. \n",
    "\n",
    "# Create a dataset of insurance compare with only Real category\n",
    "#df_insurance_compare_test = df_insurance_compare_test.loc[df_insurance_compare_test['Data'] == 'Real'] \n",
    "\n",
    "df_insurance_compare_test = df_insurance_compare_test.drop('region', axis=1) # drop column that are not useful\n",
    "df_insurance_compare_test = df_insurance_compare_test.drop('Data', axis=1) # drop all the NA values from Data column\n",
    "df_insurance_compare_test = df_insurance_compare_test.to_numpy() # this transforms the code into a matrix in order to run the next line of code.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "65a9c8d29e683726",
   "outputs": [],
   "execution_count": 123
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "655b2d8943d101a7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "ca2cfb46d2807209"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T00:24:56.704503Z",
     "start_time": "2024-07-23T00:24:56.696319Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Making the correlation matrix\n",
    "r_corr = np.corrcoef(df_insurance_compare_test.T) # Here you need to transpose the data so it makes sense\n",
    "#r_corr # this code prints the correlation matrix. Note if I use print it also works the only differences is that it outputs in pure python form\n",
    "\n",
    "synthethic_data_csv_VF = synthethic_data_csv_VF.drop('Data', axis=1) # Drop the column Data from the test_data\n",
    "synthethic_data_csv_VF = synthethic_data_csv_VF.to_numpy() # change the data frame into a matrix\n",
    "t_corr = np.corrcoef(synthethic_data_csv_VF.T) # Run a correlation matrix\n",
    "delta = np.abs(t_corr - r_corr) # calculating the delta or difference between the correlation matrices of both test sets. The nearest to 0 the best match. \n",
    "dim = delta.shape[0]   # number of features\n",
    "\n"
   ],
   "id": "f15d7bc854277084",
   "outputs": [],
   "execution_count": 124
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+00, 3.54682647e-02, 2.57939103e-02, 3.03263092e-02,\n",
       "        7.61611657e-02, 3.48588510e-02],\n",
       "       [3.54682647e-02, 0.00000000e+00, 1.97539205e-02, 3.44522526e-02,\n",
       "        5.03632348e-02, 4.29449949e-02],\n",
       "       [2.57939103e-02, 1.97539205e-02, 0.00000000e+00, 1.27354446e-02,\n",
       "        7.56344449e-02, 6.88635199e-02],\n",
       "       [3.03263092e-02, 3.44522526e-02, 1.27354446e-02, 2.22044605e-16,\n",
       "        2.81643715e-02, 2.07733288e-04],\n",
       "       [7.61611657e-02, 5.03632348e-02, 7.56344449e-02, 2.81643715e-02,\n",
       "        0.00000000e+00, 5.44811646e-03],\n",
       "       [3.48588510e-02, 4.29449949e-02, 6.88635199e-02, 2.07733288e-04,\n",
       "        5.44811646e-03, 0.00000000e+00]])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 126,
   "source": "",
   "id": "4f99092d0e57e928"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Making the kolmogorov smirnov procedure\n",
    "\n",
    "- I need to change the names of the df_insurance_compare_test when converting to the matrix"
   ],
   "id": "7faccddcb1654603"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T00:30:53.401228Z",
     "start_time": "2024-07-23T00:30:53.384862Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ks = np.zeros(dim) # Here I want to calculate the Kolmogorov-Smirnov distance remember that the lower the distance the better. Lower distance means more similarity. \n",
    "\n",
    "# Here the str is different because there aren't so any categories just one.\n",
    "\n",
    "out_of_range = 0\n",
    "for idx in range(dim): # This for loop just loops throw all the m columns \n",
    "        dr = df_insurance_compare_test[:,idx]\n",
    "        dt = synthethic_data_csv_VF[:,idx]\n",
    "        stats = ks_2samp(dr, dt)\n",
    "        ks[idx] = stats.statistic # Calculate the Kolmogorov-Smirnov distance throw all the columns\n",
    "        if np.min(dt) < np.min(dr) or np.max(dt) > np.max(dr):\n",
    "            out_of_range = 1\n",
    "str = \"%8.6f %8.6f %8.6f %8.6f %1d\" % (np.mean(delta), \n",
    "              np.max(delta), np.mean(ks), np.max(ks), out_of_range)\n",
    "print(str)"
   ],
   "id": "c6e358321b52382e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.030065 0.076161 0.041916 0.088323 0\n"
     ]
    }
   ],
   "execution_count": 131
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "fb5e78be53ee43bd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Aquí me quedé ya hice la diferencia de las matrices",
   "id": "ce9da2d00ad3f849"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-22T23:21:58.381020Z",
     "start_time": "2024-07-22T23:21:58.375532Z"
    }
   },
   "cell_type": "code",
   "source": "t_corr\n",
   "id": "a1f94a2eab45b6d3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.02401328,  0.11469934,  0.05616986,  0.02781445,\n",
       "         0.30359904],\n",
       "       [ 0.02401328,  1.        , -0.06099058,  0.01369302, -0.10271203,\n",
       "        -0.10006806],\n",
       "       [ 0.11469934, -0.06099058,  1.        , -0.02956176, -0.0472298 ,\n",
       "         0.14075439],\n",
       "       [ 0.05616986,  0.01369302, -0.02956176,  1.        ,  0.04339566,\n",
       "         0.08864835],\n",
       "       [ 0.02781445, -0.10271203, -0.0472298 ,  0.04339566,  1.        ,\n",
       "         0.79796278],\n",
       "       [ 0.30359904, -0.10006806,  0.14075439,  0.08864835,  0.79796278,\n",
       "         1.        ]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 82
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Open the synthetics data created from the other synthethic data",
   "id": "d36ea976877fa99e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T20:27:25.236148Z",
     "start_time": "2024-07-17T20:27:25.137854Z"
    }
   },
   "cell_type": "code",
   "source": [
    "synthetic_synthetic_data = 'insurance_synth_synth.txt'\n",
    "\n",
    "raw_data_synthetic_synthetic = url2+synthetic_synthetic_data\n",
    "data_2synthethic = pd.read_csv(raw_data_synthetic_synthetic, sep=\"\\t\", header=None)\n",
    "data_2synthethic.columns = [\"sex\", \"smoker\", \"region\", \"age\", \"bmi\", \"children\", \"charges\"]\n",
    "data_2synthethic['Data'] = \"Synthetic\"\n",
    "data_2synthethic = data_2synthethic[['Data', 'age', 'sex', 'bmi', 'children', 'smoker', 'region', 'charges']]\n",
    "\n",
    "# Now this is a .csv file called synthethic_synthethic_data.csv\n"
   ],
   "id": "8e1a1130450efb0",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Joining the data of both synthethic\n",
   "id": "14892af0582f9e52"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "synthetic_synthetic_data_VF = 'synthetic_synthetic_data.csv'\n",
    "\n",
    "raw_data_synthetic_synthetic_VF = url2+synthetic_synthetic_data_VF\n",
    "data_2synthethic_VF = pd.read_csv(raw_data_synthetic_synthetic_VF)\n",
    "\n",
    "data_2synthethic_VF = data_2synthethic_VF[:-1]\n",
    "\n",
    "data_3synthethic_VF = pd.concat([data_synthethic_VF,data_2synthethic_VF],ignore_index=True, axis=0)\n",
    "\n"
   ],
   "id": "ec7007b14484c40c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Now check the synthethization and its performance",
   "id": "9d648c8836630f93"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "300ede46364f9216"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
