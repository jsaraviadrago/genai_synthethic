{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# This the task for GEN-AI from Vincent's Granvilles book \"Synthetic Data and Generative AI\"\n",
    "\n",
    "The first thing is to import the packages"
   ],
   "id": "99a030b922322153"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-17T16:55:42.807404Z",
     "start_time": "2024-07-17T16:55:36.216945Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy.stats import ks_2samp\n",
    "from statsmodels.distributions.empirical_distribution import ECDF\n",
    "from scipy.stats import norm\n",
    "import csv\n",
    "\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Reading the data from Github from the Vincent Granville's [repo](https://github.com/VincentGranville/Main) \n",
    "\n",
    "The link for the project book is [here](https://github.com/VincentGranville/Large-Language-Models/blob/main/Projects4.pdf)"
   ],
   "id": "fb7cc49a2e0153a3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T16:57:34.727564Z",
     "start_time": "2024-07-17T16:57:32.994900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Selecting the needed data frames according to the project book. \n",
    "insurance = 'insurance.csv'\n",
    "insurance_compare = 'insurance_compare.csv'\n",
    "insurance_compare_holdout = 'insurance_compare_holdout.csv'\n",
    "insurance_compare_train = 'insurance_compare_train.csv'\n",
    "insurance_compare_test = 'insurance_compare_test.csv'\n",
    "\n",
    "\n",
    "# Getting the URL\n",
    "url = \"https://raw.githubusercontent.com/VincentGranville/Main/main/\"\n",
    "url2 = \"https://raw.githubusercontent.com/jsaraviadrago/genai_synthethic/main/\"\n",
    "\n",
    "# Separating the raw data frames\n",
    "raw_insurance =  url + insurance \n",
    "raw_insurance_compare = url + insurance_compare \n",
    "raw_insurance_compare_update = url2 + insurance_compare\n",
    "raw_insurance_compare_holdout = url + insurance_compare_holdout\n",
    "raw_insurance_compare_train = url2 + insurance_compare_train\n",
    "raw_insurance_compare_test = url2 + insurance_compare_test\n",
    "\n",
    "# Opening the links with pandas.\n",
    "df_insurance = pd.read_csv(raw_insurance) #step 1\n",
    "df_insurance_compare = pd.read_csv(raw_insurance_compare) # step 2\n",
    "df_insurance_compare_update = pd.read_csv(raw_insurance_compare_update) #step 3 to add the generated data\n",
    "df_insurance_compare_holdout = pd.read_csv(raw_insurance_compare_holdout) #step 3 to understand what should be the result\n",
    "df_insurance_compare_train = pd.read_csv(raw_insurance_compare_train) # step 3 get the training set from the repo\n",
    "df_insurance_compare_test = pd.read_csv(raw_insurance_compare_test) # step 3 get the training set from the repo\n",
    "\n"
   ],
   "id": "c7cced62241d1f8b",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Step 1: Making the histograms for the numerical variables ",
   "id": "aa25d2d542ee9d25"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig, axs = plt.subplots(2, 2)\n",
    "axs[0, 0].hist(df_insurance['age'])\n",
    "axs[0, 0].set_title(\"Age\")\n",
    "axs[1, 0].hist(df_insurance['charges'])\n",
    "axs[1, 0].set_title(\"Charges\")\n",
    "axs[0, 1].hist(df_insurance['bmi'])\n",
    "axs[0, 1].set_title(\"Bmi\")\n",
    "fig.tight_layout()\n",
    "\n",
    "\n"
   ],
   "id": "b0e1292e7cd095cd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Step 2: perform evaluations of vendor comparisons\n",
    "\n",
    "Preparing the data to make some analysis. \n",
    "- Drop columns\n",
    "- Erase NA values"
   ],
   "id": "f5d626f00232f499"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T16:57:52.326613Z",
     "start_time": "2024-07-17T16:57:52.316392Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Watch out with this code, since I am overwriting the dataset you need to run first the second cell or an error will be thrown. This can be fixed if you use a script. \n",
    "\n",
    "df_insurance_compare = df_insurance_compare.drop('region', axis=1) # drop columns that are not useful\n",
    "df_insurance_compare = df_insurance_compare.dropna(axis='columns') # Drop na row wise. \n",
    "\n",
    "# Create a dataset of insurance compare with only Real category\n",
    "df_insurance_compare_real = df_insurance_compare.loc[df_insurance_compare['Data'] == 'Real'] \n",
    "\n",
    "df_insurance_compare_real = df_insurance_compare_real.drop('Data', axis=1) # drop all the NA values from Data column\n",
    "df_insurance_compare_real = df_insurance_compare_real.to_numpy() # this transforms the code into a matrix in order to run the next line of code.\n",
    "\n"
   ],
   "id": "707a468d582fa2b9",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Step 2.1: run the analysis after preparing the data\n",
    "\n",
    "What did I do here? \n",
    "- Correlation matrix\n",
    "- Drop the real category from the original data frame called ```df_insurance_compare```"
   ],
   "id": "e71c6f6bf4d6fc62"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "edb2c5c5735f8b8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T16:58:07.441826Z",
     "start_time": "2024-07-17T16:58:07.435540Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Making a correlation matrix with coefficients\n",
    "r_corr = np.corrcoef(df_insurance_compare_real.T) # Here you need to transpose the data so it makes sense\n",
    "\n",
    "#r_corr # this code prints the correlation matrix. Note if I use print it also works the only differences is that it outputs in pure python form\n",
    "\n",
    "ltests = df_insurance_compare.Data.unique().tolist() # Here it just shows all the unique categories of the Data variable\n",
    "popped_item = ltests.pop(0)   # remove real data from the tests\n",
    "#print(ltests) # it just prints that the ltests object does not have the \"Real\" category\n",
    "\n"
   ],
   "id": "631d0b20e21e406",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Step 2.2: run the analysis to check for the data\n",
    "\n",
    "- Calculate the distance of the correlation matrix\n",
    "- Calculate the distance of the Kolmogorov-Smirnov "
   ],
   "id": "93582734727abd32"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T16:58:10.973492Z",
     "start_time": "2024-07-17T16:58:10.927976Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for test in ltests:\n",
    "\n",
    "    data_test = df_insurance_compare.loc[df_insurance_compare['Data'] == test] # select the category test\n",
    "    data_test = data_test.drop('Data', axis=1) # Drop the column Data from the test_data\n",
    "    data_test = data_test.to_numpy() # change the data frame into a matrix\n",
    "    t_corr = np.corrcoef(data_test.T) # Run a correlation matrix\n",
    "    delta = np.abs(t_corr - r_corr) # calculating the delta or difference between the correlation matrices of both test sets. The nearest to 0 the best match. \n",
    "    dim = delta.shape[0]   # number of features\n",
    "  \n",
    "    ks = np.zeros(dim) # Here I want to calculate the Kolmogorov-Smirnov distance remember that the lower the distance the better. Lower distance means more similarity. \n",
    "    out_of_range = 0\n",
    "    for idx in range(dim): # This for loop just loops throw all the m columns \n",
    "        dr = df_insurance_compare_real[:,idx]\n",
    "        dt = data_test[:,idx]\n",
    "        stats = ks_2samp(dr, dt)\n",
    "        ks[idx] = stats.statistic # Calculate the Kolmogorov-Smirnov distance throw all the columns\n",
    "        if np.min(dt) < np.min(dr) or np.max(dt) > np.max(dr):\n",
    "            out_of_range = 1\n",
    "    str = \"%20s %14s %8.6f %8.6f %8.6f %8.6f %1d\" % (insurance_compare, test, np.mean(delta), \n",
    "              np.max(delta), np.mean(ks), np.max(ks), out_of_range)\n",
    "    print(str)\n",
    "    \n"
   ],
   "id": "a1a45888a898a7d5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "insurance_compare.csv         YData1 0.015844 0.051774 0.020227 0.030059 0\n",
      "insurance_compare.csv         YData2 0.017100 0.052157 0.022297 0.028401 0\n",
      "insurance_compare.csv         Gretel 0.021085 0.092606 0.040011 0.086254 0\n",
      "insurance_compare.csv            SDV 0.033703 0.350682 0.093176 0.213358 0\n",
      "insurance_compare.csv  Synthesize.io 0.025702 0.070506 0.025870 0.040396 0\n",
      "insurance_compare.csv      VG_Copula 0.013471 0.049100 0.016442 0.032885 0\n",
      "insurance_compare.csv      Mostly.ai 0.017264 0.057882 0.023169 0.041854 0\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "e752f7b3d92d5a75"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Step 2.3: create the scatterplot\n",
    "\n",
    "Creating a function for the scatterplot\n",
    "\n"
   ],
   "id": "20bd3b6fbf0b3a4a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def vg_scatter(df_insurance_compare, test, counter):\n",
    "\n",
    "    # customized plots, insurance data \n",
    "    # one of 6 plots, subplot position based on counter\n",
    "\n",
    "    data_plot = df_insurance_compare.loc[df_insurance_compare['Data'] == test]\n",
    "    x = data_plot[['age']].to_numpy()\n",
    "    y = data_plot[['charges']].to_numpy()\n",
    "    plt.subplot(2, 3, counter)\n",
    "    plt.scatter(x, y, s = 0.1, c =\"blue\")\n",
    "    plt.xlabel(test, fontsize = 7)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.ylim(0,70000)\n",
    "    plt.xlim(18,64)\n",
    "    return()\n",
    "\n",
    "# Set the linewidth for axes\n",
    "mpl.rcParams['axes.linewidth'] = 0.3\n",
    "\n",
    "# Plot each scatter plot\n",
    "vg_scatter(df_insurance_compare, 'Real', 1)\n",
    "vg_scatter(df_insurance_compare, 'YData1', 2)\n",
    "vg_scatter(df_insurance_compare, 'Gretel', 3)\n",
    "vg_scatter(df_insurance_compare, 'Mostly.ai', 4)\n",
    "vg_scatter(df_insurance_compare, 'Synthesize.io', 5)\n",
    "vg_scatter(df_insurance_compare, 'SDV', 6)\n",
    "\n",
    "plt.tight_layout() # Just to fit it in a nice size. \n",
    "plt.show()\n",
    "\n"
   ],
   "id": "419afe81ed7c0460",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Step 2.4: Create the histogram\n",
    "\n",
    "Creating a function for the histogram and plotting the histogram\n",
    "\n",
    "\n"
   ],
   "id": "91c054a1a4afbd58"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def vg_histo(df, test, counter):\n",
    "\n",
    "    # customized plots, insurance data \n",
    "    # one of 6 plots, subplot position based on counter\n",
    "\n",
    "    data_plot = df_insurance_compare.loc[df['Data'] == test]\n",
    "    y = data_plot[['charges']].to_numpy()\n",
    "    plt.subplot(2, 3, counter)\n",
    "    binBoundaries = np.linspace(0, 70000, 30)\n",
    "    plt.hist(y, bins=binBoundaries, color='white', align='mid',edgecolor='red',\n",
    "              linewidth = 0.3) \n",
    "    plt.xlabel(test, fontsize = 7)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.xlim(0,70000)\n",
    "    plt.ylim(0, 250)\n",
    "    return()\n",
    "\n",
    "# Set the linewidth for axes\n",
    "mpl.rcParams['axes.linewidth'] = 0.3\n",
    "\n",
    "vg_histo(df_insurance_compare, 'Real', 1)\n",
    "vg_histo(df_insurance_compare, 'YData1', 2)\n",
    "vg_histo(df_insurance_compare, 'Gretel', 3)\n",
    "vg_histo(df_insurance_compare, 'Mostly.ai', 4)\n",
    "vg_histo(df_insurance_compare, 'Synthesize.io', 5)\n",
    "vg_histo(df_insurance_compare, 'SDV', 6)\n",
    "\n",
    "plt.tight_layout() # Just to fit it in a nice size. \n",
    "plt.show()"
   ],
   "id": "5fd74a26f9dd723d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Step 3: Produce a file similar to insurance compare holdout.csv but for a vendor other than YData.ai\n",
    "\n",
    "The holdout data has 50% of the rows of validate, train and Ydata. There is also 669 Ydata2 which is the synthethic data. So, in order to start working with the insurance_compare data you need to first use the first half of the real category as explained in the book. \n",
    "\n",
    "**Note:** Probably in other methods you could hold data randomly. \n"
   ],
   "id": "97fdbe66cabc5cc6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_insurance_compare_holdout.info() # inspecting the whole data frame\n",
    "\n",
    "# Inspecting the data there 4 categories and Ydata1 has been used to create 669 new rows named Ydata2\n",
    "df_insurance_compare_holdout['Data'].value_counts() # counting categories of data\n",
    "\n"
   ],
   "id": "a4473b2b84d8754a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "b38b774eb37f30da"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Step 3.1: this was done in the script. Script_insurance_synthethic_data.py",
   "id": "fbce323164ba8f4c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T20:24:32.151091Z",
     "start_time": "2024-07-17T20:24:31.345310Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Calling the output data from that script.\n",
    "\n",
    "synthetic_data = 'insurance_synth.txt'\n",
    "\n",
    "raw_data_synthetic = url2+synthetic_data\n",
    "data = pd.read_csv(raw_data_synthetic, sep=\"\\t\", header=None)\n",
    "data.columns = [\"sex\", \"smoker\", \"region\", \"age\", \"bmi\", \"children\", \"charges\"]\n",
    "data['Data'] = \"Synthetic\"\n",
    "data = data[['Data', 'age', 'sex', 'bmi', 'children', 'smoker', 'region', 'charges']]\n",
    "\n",
    "#data.to_csv('C:\\\\Users\\\\JuanCarlosSaraviaDra\\\\Downloads\\\\synthetic_data.csv', index=False)\n",
    "\n",
    "\n"
   ],
   "id": "87161f410d5d5ed5",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "68fb30648c364039",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T17:10:05.893965Z",
     "start_time": "2024-07-17T17:10:05.889071Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Making the data similar \n",
    "# = df_insurance_compare_test.drop(['Unnamed: 0','Unnamed: 8', 'Unnamed: 9', 'Unnamed: 10'],axis=1)\n",
    "df_insurance_compare_test.shape[0]\n"
   ],
   "id": "fd9f364b6e564412",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "668"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Now check the quality of the synthethization using the correlation distance matrix and KM distance",
   "id": "c9e4d13547a0ad76"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Now check the quality of the synthethization using the correlation distance matrix and KM distance\n",
    "synthethic_data_csv = 'synthetic_data.csv' # Calling the synthethise data. \n",
    "\n",
    "data_synthethic_VF = pd.read_csv(url2+synthethic_data_csv) # Reading the data\n",
    "\n",
    "data_synthethic_VF = data_synthethic_VF[:-1] # Dropping the last row so both datasets have the same amount of lines\n",
    "\n",
    "# Row binding the data. \n",
    "data_synthethic_test_VF = pd.concat([data_synthethic_VF, df_insurance_compare_test], ignore_index=True, axis=0)\n"
   ],
   "id": "65a9c8d29e683726",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Open the synthetics data created from the other synthethic data",
   "id": "d36ea976877fa99e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "synthetic_synthetic_data = 'insurance_synth_synth.txt'\n",
    "\n",
    "raw_data_synthetic_synthetic = url2+synthetic_synthetic_data\n",
    "data_2synthethic = pd.read_csv(raw_data_synthetic_synthetic, sep=\"\\t\", header=None)\n",
    "data_2synthethic.columns = [\"sex\", \"smoker\", \"region\", \"age\", \"bmi\", \"children\", \"charges\"]\n",
    "data_2synthethic['Data'] = \"Synthetic\"\n",
    "data_2synthethic = data_2synthethic[['Data', 'age', 'sex', 'bmi', 'children', 'smoker', 'region', 'charges']]\n",
    "\n",
    "data_2synthethic.head()\n",
    "#data.to_csv('C:\\\\Users\\\\JuanCarlosSaraviaDra\\\\Downloads\\\\synthetic_data.csv', index=False)\n"
   ],
   "id": "8e1a1130450efb0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Now check the synthethization and its performance",
   "id": "14892af0582f9e52"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
