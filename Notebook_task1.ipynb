{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# This the task for GEN-AI from Vincent's Granvilles book \"Synthetic Data and Generative AI\"\n",
    "\n",
    "The first thing is to import the packages"
   ],
   "id": "99a030b922322153"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-22T22:25:05.594270Z",
     "start_time": "2024-07-22T22:25:05.570538Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy.stats import ks_2samp\n",
    "from statsmodels.distributions.empirical_distribution import ECDF\n",
    "from scipy.stats import norm\n",
    "import csv\n",
    "\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Reading the data from Github from the Vincent Granville's [repo](https://github.com/VincentGranville/Main) \n",
    "\n",
    "The link for the project book is [here](https://github.com/VincentGranville/Large-Language-Models/blob/main/Projects4.pdf)"
   ],
   "id": "fb7cc49a2e0153a3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-22T22:25:24.082012Z",
     "start_time": "2024-07-22T22:25:09.574223Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Selecting the needed data frames according to the project book. \n",
    "insurance = 'insurance.csv'\n",
    "insurance_compare = 'insurance_compare.csv'\n",
    "insurance_compare_holdout = 'insurance_compare_holdout.csv'\n",
    "insurance_compare_train = 'insurance_compare_train.csv'\n",
    "insurance_compare_test = 'insurance_compare_test.csv'\n",
    "\n",
    "\n",
    "# Getting the URL\n",
    "url = \"https://raw.githubusercontent.com/VincentGranville/Main/main/\"\n",
    "url2 = \"https://raw.githubusercontent.com/jsaraviadrago/genai_synthethic/main/\"\n",
    "\n",
    "# Separating the raw data frames\n",
    "raw_insurance =  url + insurance \n",
    "raw_insurance_compare = url + insurance_compare \n",
    "raw_insurance_compare_update = url2 + insurance_compare\n",
    "raw_insurance_compare_holdout = url + insurance_compare_holdout\n",
    "raw_insurance_compare_train = url2 + insurance_compare_train\n",
    "raw_insurance_compare_test = url2 + insurance_compare_test\n",
    "\n",
    "# Opening the links with pandas.\n",
    "df_insurance = pd.read_csv(raw_insurance) #step 1\n",
    "df_insurance_compare = pd.read_csv(raw_insurance_compare) # step 2\n",
    "df_insurance_compare_update = pd.read_csv(raw_insurance_compare_update) #step 3 to add the generated data\n",
    "df_insurance_compare_holdout = pd.read_csv(raw_insurance_compare_holdout) #step 3 to understand what should be the result\n",
    "df_insurance_compare_train = pd.read_csv(raw_insurance_compare_train) # step 3 get the training set from the repo\n",
    "df_insurance_compare_test = pd.read_csv(raw_insurance_compare_test) # step 3 get the training set from the repo\n",
    "\n"
   ],
   "id": "c7cced62241d1f8b",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Step 1: Making the histograms for the numerical variables ",
   "id": "aa25d2d542ee9d25"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig, axs = plt.subplots(2, 2)\n",
    "axs[0, 0].hist(df_insurance['age'])\n",
    "axs[0, 0].set_title(\"Age\")\n",
    "axs[1, 0].hist(df_insurance['charges'])\n",
    "axs[1, 0].set_title(\"Charges\")\n",
    "axs[0, 1].hist(df_insurance['bmi'])\n",
    "axs[0, 1].set_title(\"Bmi\")\n",
    "fig.tight_layout()\n",
    "\n",
    "\n"
   ],
   "id": "b0e1292e7cd095cd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Step 2: perform evaluations of vendor comparisons\n",
    "\n",
    "Preparing the data to make some analysis. \n",
    "- Drop columns\n",
    "- Erase NA values"
   ],
   "id": "f5d626f00232f499"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-22T20:43:17.447119Z",
     "start_time": "2024-07-22T20:43:17.436287Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Watch out with this code, since I am overwriting the dataset you need to run first the second cell or an error will be thrown. This can be fixed if you use a script. \n",
    "\n",
    "df_insurance_compare = df_insurance_compare.drop('region', axis=1) # drop columns that are not useful\n",
    "df_insurance_compare = df_insurance_compare.dropna(axis='columns') # Drop na row wise. \n",
    "\n",
    "# Create a dataset of insurance compare with only Real category\n",
    "df_insurance_compare_real = df_insurance_compare.loc[df_insurance_compare['Data'] == 'Real'] \n",
    "\n",
    "df_insurance_compare_real = df_insurance_compare_real.drop('Data', axis=1) # drop all the NA values from Data column\n",
    "df_insurance_compare_real = df_insurance_compare_real.to_numpy() # this transforms the code into a matrix in order to run the next line of code.\n",
    "\n"
   ],
   "id": "707a468d582fa2b9",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Step 2.1: run the analysis after preparing the data\n",
    "\n",
    "What did I do here? \n",
    "- Correlation matrix\n",
    "- Drop the real category from the original data frame called ```df_insurance_compare```"
   ],
   "id": "e71c6f6bf4d6fc62"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "edb2c5c5735f8b8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-22T20:44:15.329842Z",
     "start_time": "2024-07-22T20:44:15.323572Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Making a correlation matrix with coefficients\n",
    "r_corr = np.corrcoef(df_insurance_compare_real.T) # Here you need to transpose the data so it makes sense\n",
    "\n",
    "#r_corr # this code prints the correlation matrix. Note if I use print it also works the only differences is that it outputs in pure python form\n",
    "\n",
    "ltests = df_insurance_compare.Data.unique().tolist() # Here it just shows all the unique categories of the Data variable\n",
    "popped_item = ltests.pop(0)   # remove real data from the tests\n",
    "#print(ltests) # it just prints that the ltests object does not have the \"Real\" category\n",
    "\n"
   ],
   "id": "631d0b20e21e406",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Step 2.2: run the analysis to check for the data\n",
    "\n",
    "- Calculate the distance of the correlation matrix\n",
    "- Calculate the distance of the Kolmogorov-Smirnov "
   ],
   "id": "93582734727abd32"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for test in ltests:\n",
    "\n",
    "    data_test = df_insurance_compare.loc[df_insurance_compare['Data'] == test] # select the category test\n",
    "    data_test = data_test.drop('Data', axis=1) # Drop the column Data from the test_data\n",
    "    data_test = data_test.to_numpy() # change the data frame into a matrix\n",
    "    t_corr = np.corrcoef(data_test.T) # Run a correlation matrix\n",
    "    delta = np.abs(t_corr - r_corr) # calculating the delta or difference between the correlation matrices of both test sets. The nearest to 0 the best match. \n",
    "    dim = delta.shape[0]   # number of features\n",
    "  \n",
    "    ks = np.zeros(dim) # Here I want to calculate the Kolmogorov-Smirnov distance remember that the lower the distance the better. Lower distance means more similarity. \n",
    "    out_of_range = 0\n",
    "    for idx in range(dim): # This for loop just loops throw all the m columns \n",
    "        dr = df_insurance_compare_real[:,idx]\n",
    "        dt = data_test[:,idx]\n",
    "        stats = ks_2samp(dr, dt)\n",
    "        ks[idx] = stats.statistic # Calculate the Kolmogorov-Smirnov distance throw all the columns\n",
    "        if np.min(dt) < np.min(dr) or np.max(dt) > np.max(dr):\n",
    "            out_of_range = 1\n",
    "    str = \"%20s %14s %8.6f %8.6f %8.6f %8.6f %1d\" % (insurance_compare, test, np.mean(delta), \n",
    "              np.max(delta), np.mean(ks), np.max(ks), out_of_range)\n",
    "    print(str)\n",
    "    \n"
   ],
   "id": "a1a45888a898a7d5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "e752f7b3d92d5a75"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Step 2.3: create the scatterplot\n",
    "\n",
    "Creating a function for the scatterplot\n",
    "\n"
   ],
   "id": "20bd3b6fbf0b3a4a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def vg_scatter(df_insurance_compare, test, counter):\n",
    "\n",
    "    # customized plots, insurance data \n",
    "    # one of 6 plots, subplot position based on counter\n",
    "\n",
    "    data_plot = df_insurance_compare.loc[df_insurance_compare['Data'] == test]\n",
    "    x = data_plot[['age']].to_numpy()\n",
    "    y = data_plot[['charges']].to_numpy()\n",
    "    plt.subplot(2, 3, counter)\n",
    "    plt.scatter(x, y, s = 0.1, c =\"blue\")\n",
    "    plt.xlabel(test, fontsize = 7)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.ylim(0,70000)\n",
    "    plt.xlim(18,64)\n",
    "    return()\n",
    "\n",
    "# Set the linewidth for axes\n",
    "mpl.rcParams['axes.linewidth'] = 0.3\n",
    "\n",
    "# Plot each scatter plot\n",
    "vg_scatter(df_insurance_compare, 'Real', 1)\n",
    "vg_scatter(df_insurance_compare, 'YData1', 2)\n",
    "vg_scatter(df_insurance_compare, 'Gretel', 3)\n",
    "vg_scatter(df_insurance_compare, 'Mostly.ai', 4)\n",
    "vg_scatter(df_insurance_compare, 'Synthesize.io', 5)\n",
    "vg_scatter(df_insurance_compare, 'SDV', 6)\n",
    "\n",
    "plt.tight_layout() # Just to fit it in a nice size. \n",
    "plt.show()\n",
    "\n"
   ],
   "id": "419afe81ed7c0460",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Step 2.4: Create the histogram\n",
    "\n",
    "Creating a function for the histogram and plotting the histogram\n",
    "\n",
    "\n"
   ],
   "id": "91c054a1a4afbd58"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def vg_histo(df, test, counter):\n",
    "\n",
    "    # customized plots, insurance data \n",
    "    # one of 6 plots, subplot position based on counter\n",
    "\n",
    "    data_plot = df_insurance_compare.loc[df['Data'] == test]\n",
    "    y = data_plot[['charges']].to_numpy()\n",
    "    plt.subplot(2, 3, counter)\n",
    "    binBoundaries = np.linspace(0, 70000, 30)\n",
    "    plt.hist(y, bins=binBoundaries, color='white', align='mid',edgecolor='red',\n",
    "              linewidth = 0.3) \n",
    "    plt.xlabel(test, fontsize = 7)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.xlim(0,70000)\n",
    "    plt.ylim(0, 250)\n",
    "    return()\n",
    "\n",
    "# Set the linewidth for axes\n",
    "mpl.rcParams['axes.linewidth'] = 0.3\n",
    "\n",
    "vg_histo(df_insurance_compare, 'Real', 1)\n",
    "vg_histo(df_insurance_compare, 'YData1', 2)\n",
    "vg_histo(df_insurance_compare, 'Gretel', 3)\n",
    "vg_histo(df_insurance_compare, 'Mostly.ai', 4)\n",
    "vg_histo(df_insurance_compare, 'Synthesize.io', 5)\n",
    "vg_histo(df_insurance_compare, 'SDV', 6)\n",
    "\n",
    "plt.tight_layout() # Just to fit it in a nice size. \n",
    "plt.show()"
   ],
   "id": "5fd74a26f9dd723d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Step 3: Produce a file similar to insurance compare holdout.csv but for a vendor other than YData.ai\n",
    "\n",
    "The holdout data has 50% of the rows of validate, train and Ydata. There is also 669 Ydata2 which is the synthethic data. So, in order to start working with the insurance_compare data you need to first use the first half of the real category as explained in the book. \n",
    "\n",
    "**Note:** Probably in other methods you could hold data randomly. \n"
   ],
   "id": "97fdbe66cabc5cc6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_insurance_compare_holdout.info() # inspecting the whole data frame\n",
    "\n",
    "# Inspecting the data there 4 categories and Ydata1 has been used to create 669 new rows named Ydata2\n",
    "df_insurance_compare_holdout['Data'].value_counts() # counting categories of data\n",
    "\n"
   ],
   "id": "a4473b2b84d8754a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "b38b774eb37f30da"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Step 3.1: this was done in the script. Script_insurance_synthethic_data.py",
   "id": "fbce323164ba8f4c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-22T22:31:43.658157Z",
     "start_time": "2024-07-22T22:31:42.890356Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Calling the output data from that script.\n",
    "\n",
    "synthetic_data = 'insurance_synth.txt'\n",
    "\n",
    "raw_data_synthetic = url2+synthetic_data\n",
    "synthethic_data_csv = pd.read_csv(raw_data_synthetic, sep=\"\\t\", header=None)\n",
    "synthethic_data_csv.columns = [\"sex\", \"smoker\", \"region\", \"age\", \"bmi\", \"children\", \"charges\"]\n",
    "synthethic_data_csv['Data'] = \"Synthetic\"\n",
    "synthethic_data_csv = synthethic_data_csv[['Data', 'age', 'sex', 'bmi', 'children', 'smoker', 'region', 'charges']]\n",
    "\n",
    "# This data in CSV is the first generated data called synthethic_data.csv\n",
    "\n",
    "\n"
   ],
   "id": "87161f410d5d5ed5",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Making the data similar to the synthethic_data.csv to test against the test\n",
    "df_insurance_compare_test = df_insurance_compare_test.drop(['Unnamed: 0','Unnamed: 8', 'Unnamed: 9', 'Unnamed: 10'],axis=1)"
   ],
   "id": "b2616a1baa299861"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Now check the quality of the synthethization using the correlation distance matrix and KM distance\n",
    "\n",
    "- First we make both datasets the same\n",
    "- Checking the quality of the data"
   ],
   "id": "c9e4d13547a0ad76"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Now check the quality of the synthethization using the correlation distance matrix and KM distance\n",
    "\n",
    "synthethic_data_csv_VF = synthethic_data_csv[:-1] # Dropping the last row so both datasets have the same amount of lines\n",
    "\n",
    "synthethic_data_csv_VF = synthethic_data_csv_VF.drop('region', axis=1) # drop columns that are not useful\n",
    "synthethic_data_csv_VF = synthethic_data_csv_VF.dropna(axis='columns') # Drop na row wise. \n",
    "\n",
    "\n",
    "\n",
    "# Create a dataset of insurance compare with only Real category\n",
    "df_insurance_compare_test = df_insurance_compare_test.loc[df_insurance_compare_test['Data'] == 'Real'] \n",
    "\n",
    "df_insurance_compare_test = df_insurance_compare_test.drop('Data', axis=1) # drop all the NA values from Data column\n",
    "df_insurance_compare_test = df_insurance_compare_test.to_numpy() # this transforms the code into a matrix in order to run the next line of code.\n"
   ],
   "id": "65a9c8d29e683726",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "ca2cfb46d2807209"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-22T22:49:44.119402Z",
     "start_time": "2024-07-22T22:49:44.109004Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#data_3synthethic_VF = pd.concat([data_synthethic_VF,data_2synthethic_VF],ignore_index=True, axis=0)\n",
    "\n",
    "#synthethic_data_csv_VF\n",
    "#df_insurance_compare_test\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "f15d7bc854277084",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     Data   age  sex    bmi  children  smoker     region   charges\n",
       "0    Real  30.0    0  31.57       3.0       0  southeast   4837.58\n",
       "1    Real  29.0    1  31.16       0.0       0  northeast   3943.60\n",
       "2    Real  36.0    0  29.70       0.0       0  southeast   4399.73\n",
       "3    Real  41.0    1  31.02       0.0       0  southeast   6185.32\n",
       "4    Real  44.0    1  43.89       2.0       1  southeast  46200.99\n",
       "..    ...   ...  ...    ...       ...     ...        ...       ...\n",
       "663  Real  50.0    0  30.97       3.0       0  northwest  10600.55\n",
       "664  Real  18.0    1  31.92       0.0       0  northeast   2205.98\n",
       "665  Real  18.0    1  36.85       0.0       0  southeast   1629.83\n",
       "666  Real  21.0    1  25.80       0.0       0  southwest   2007.95\n",
       "667  Real  61.0    1  29.07       0.0       1  northwest  29141.36\n",
       "\n",
       "[668 rows x 8 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Real</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>31.57</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>southeast</td>\n",
       "      <td>4837.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Real</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1</td>\n",
       "      <td>31.16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>northeast</td>\n",
       "      <td>3943.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Real</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0</td>\n",
       "      <td>29.70</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>southeast</td>\n",
       "      <td>4399.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Real</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1</td>\n",
       "      <td>31.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>southeast</td>\n",
       "      <td>6185.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Real</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1</td>\n",
       "      <td>43.89</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>southeast</td>\n",
       "      <td>46200.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663</th>\n",
       "      <td>Real</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.97</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>northwest</td>\n",
       "      <td>10600.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664</th>\n",
       "      <td>Real</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1</td>\n",
       "      <td>31.92</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>northeast</td>\n",
       "      <td>2205.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665</th>\n",
       "      <td>Real</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1</td>\n",
       "      <td>36.85</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1629.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>Real</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1</td>\n",
       "      <td>25.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>southwest</td>\n",
       "      <td>2007.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>Real</td>\n",
       "      <td>61.0</td>\n",
       "      <td>1</td>\n",
       "      <td>29.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>northwest</td>\n",
       "      <td>29141.36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>668 rows × 8 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Making a correlation matrix with coefficients\n",
    "r_corr = np.corrcoef(data_synthethic_test_VF_real.T) # Here you need to transpose the data so it makes sense\n",
    "\n",
    "#r_corr # this code prints the correlation matrix. Note if I use print it also works the only differences is that it outputs in pure python form\n",
    "\n",
    "ltests = df_insurance_compare.Data.unique().tolist() # Here it just shows all the unique categories of the Data variable\n",
    "popped_item = ltests.pop(0)   # remove real data from the tests\n",
    "#print(ltests) # it just prints that the ltests object does not have the \"Real\" category\n"
   ],
   "id": "a1f94a2eab45b6d3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Open the synthetics data created from the other synthethic data",
   "id": "d36ea976877fa99e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T20:27:25.236148Z",
     "start_time": "2024-07-17T20:27:25.137854Z"
    }
   },
   "cell_type": "code",
   "source": [
    "synthetic_synthetic_data = 'insurance_synth_synth.txt'\n",
    "\n",
    "raw_data_synthetic_synthetic = url2+synthetic_synthetic_data\n",
    "data_2synthethic = pd.read_csv(raw_data_synthetic_synthetic, sep=\"\\t\", header=None)\n",
    "data_2synthethic.columns = [\"sex\", \"smoker\", \"region\", \"age\", \"bmi\", \"children\", \"charges\"]\n",
    "data_2synthethic['Data'] = \"Synthetic\"\n",
    "data_2synthethic = data_2synthethic[['Data', 'age', 'sex', 'bmi', 'children', 'smoker', 'region', 'charges']]\n",
    "\n",
    "# Now this is a .csv file called synthethic_synthethic_data.csv\n"
   ],
   "id": "8e1a1130450efb0",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Joining the data of both synthethic\n",
   "id": "14892af0582f9e52"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "synthetic_synthetic_data_VF = 'synthetic_synthetic_data.csv'\n",
    "\n",
    "raw_data_synthetic_synthetic_VF = url2+synthetic_synthetic_data_VF\n",
    "data_2synthethic_VF = pd.read_csv(raw_data_synthetic_synthetic_VF)\n",
    "\n",
    "data_2synthethic_VF = data_2synthethic_VF[:-1]\n",
    "\n",
    "data_3synthethic_VF = pd.concat([data_synthethic_VF,data_2synthethic_VF],ignore_index=True, axis=0)\n",
    "\n"
   ],
   "id": "ec7007b14484c40c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Now check the synthethization and its performance",
   "id": "9d648c8836630f93"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "300ede46364f9216"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
